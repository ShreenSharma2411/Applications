{"name":"Concat Columns","uuid":"e02a4779-04fb-4c88-b7e4-233034b2550b","category":"Concat Columns","description":"Concatenates the values of the given columns","parameters":"-","nodes":[{"id":"2","name":"ConcatColumns","description":"This node creates a new DataFrame by concatenating the specified columns of the input DataFrame","details":"","examples":"","type":"transform","nodeClass":"fire.nodes.etl.NodeConcatColumns","x":"480px","y":"146.667px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"inputCols","value":"[\"Name\",\"Sex\",\"Age\"]","widget":"variables","title":"Columns","description":"Columns to be concatenated","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"outputCol","value":"Name_Sex_Age","widget":"textfield","title":"Concatenated Column Name","description":"Column name for the concatenated columns","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"sep","value":"|","widget":"textfield","title":"Separator","description":"Separator to be used when concatenating the columns","required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"3","name":"DatasetStructured","description":"This Node creates a DataFrame by reading data from HDFS, HIVE etc. The dataset has been defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.","details":"This Node creates a DataFrame by reading data from HDFS, HIVE etc.\u003cbr\u003e\n\u003cbr\u003e\nThe data has been defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.\u003cbr\u003e","examples":"","type":"dataset","nodeClass":"fire.nodes.dataset.NodeDatasetStructured","x":"156px","y":"151.646px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"dataset","value":"6fe6f5ec-5dca-453f-8f51-af31a96ebf63","widget":"dataset","title":"Dataset","description":"Selected Dataset","required":true,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"4","name":"PrintNRows","description":"Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output","details":"","examples":"","type":"transform","nodeClass":"fire.nodes.util.NodePrintFirstNRows","x":"809px","y":"137.646px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"title","value":"Row Values","widget":"textfield","title":"Title","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"n","value":"3","widget":"textfield","title":"Num Rows to Print","description":"number of rows to be printed","required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"5","name":"Documentation","description":"Allows capturing Notes on the Workflow","details":"","examples":"","type":"doc","nodeClass":"fire.nodes.doc.NodeDocLarge","x":"310px","y":"421.656px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"comment","value":"\u003ch1\u003eAnalyzing Workflow using Concatcolumn Node\u003c/h1\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eIt demonstrate the creating ETL workflow to concat the selcted fields from input dataframe with separator.\u003c/li\u003e\u003c/ul\u003e","widget":"textarea_rich","title":"Comment","description":"Comments for the Workflow","required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"}],"edges":[{"source":"3","target":"2","id":1},{"source":"2","target":"4","id":2}],"dataSetDetails":[{"id":15,"uuid":"6fe6f5ec-5dca-453f-8f51-af31a96ebf63","header":true,"path":"data/titanic_dat/train.tsv","delimiter":"\\t","datasetType":"CSV","filterLinesContaining":"PassengerId","datasetSchema":"{\"colNames\":[\"PassengerId\",\"Survived\",\"Pclass\",\"Name\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Ticket\",\"Fare\",\"Cabin\",\"Embarked\"],\"colTypes\":[\"INTEGER\",\"INTEGER\",\"INTEGER\",\"STRING\",\"STRING\",\"STRING\",\"INTEGER\",\"INTEGER\",\"STRING\",\"DOUBLE\",\"STRING\",\"STRING\"],\"colFormats\":[],\"colMLTypes\":[\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"TEXT\",\"TEXT\",\"TEXT\",\"NUMERIC\",\"NUMERIC\",\"TEXT\",\"NUMERIC\",\"TEXT\",\"TEXT\"]}"}],"engine":"scala"}