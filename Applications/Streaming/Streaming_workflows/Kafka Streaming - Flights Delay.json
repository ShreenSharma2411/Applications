{"name":"Kafka Streaming - Flights Delay","uuid":"1cdd8991-569c-4431-8c31-34865d722d77","category":"Flights Delay","description":"Find flights which are delayed by more than 5 minutes and plots them on a graph","nodes":[{"id":"1","name":"Streaming Kafka","description":"Reads in streaming text from topics in Apache Kafka","details":"","examples":"","type":"sparkstreaming","nodeClass":"fire.nodes.streaming.NodeStreamingKafka","x":"63.2109px","y":"51.3594px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"batchDuration","value":"30","widget":"textfield","title":"Batch Duration in Seconds","description":"Batch Duration in Seconds","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"brokers","value":"localhost:9092","widget":"textfield","title":"Kafka Brokers","description":"Kafka Brokers","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"group","value":"21","widget":"textfield","title":"Consumer Group","description":"Consumer Group","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"topics","value":"flights","widget":"textfield","title":"Kafka Topics","description":"List of Topics separated by , (comma)","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"autoOffsetReset","value":"latest","widget":"textfield","title":"auto.offset.reset","description":"Auto Offset Reset","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"enableAutoCommit","value":"true","widget":"textfield","title":"enable.auto.commit","description":"Enable Auto Commit","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"kafkaParamsKeys","value":"[]","widget":"key_array","title":"Params Key/Value Pairs","description":"More Config Values","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"kafkaParamsValues","value":"[]","widget":"value_array","title":"Parms Key/Value Pairs","description":"More Config Values","required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"2","name":"PrintNRows","description":"Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output","details":"","examples":"","type":"transform","nodeClass":"fire.nodes.util.NodePrintFirstNRows","x":"783.199px","y":"262.328px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"title","value":"Row Values","widget":"textfield","title":"Title","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"n","value":"10","widget":"textfield","title":"Num Rows to Print","description":"number of rows to be printed","required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"3","name":"Documentation","description":"Allows capturing Notes on the Workflow","details":"","examples":"","type":"doc","nodeClass":"fire.nodes.doc.NodeDocLarge","x":"377.082px","y":"435.055px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"comment","value":"\u003ch1\u003eKafka Streaming Workflow\u003c/h1\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\u003ch2\u003eThis workflow reads in events from the Kafka topic \u0027\u003cstrong\u003eflights\u003c/strong\u003e\u0027\u003c/h2\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe Mini Batch Duration for spark streaming is 30 seconds\u003c/li\u003e\u003cli\u003e​It finds the total number of flights Originating from an airport and being delayed by greater than certain duration.\u003c/li\u003e\u003cli\u003eIt plots that data in a graph with the airport code being on the X-axis.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\u003ch3\u003e\u003cstrong\u003eStart Kafka and create Topic \u0027flights\u0027\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e​The quick start guide of Kafka is at :\u0026nbsp;\u003cstrong\u003ehttps://kafka.apache.org/quickstart\u003c/strong\u003e\u003c/li\u003e\u003cli\u003eCreate the topic \u0027\u003cstrong\u003eflights\u003c/strong\u003e\u0027\u003c/li\u003e\u003cli class\u003d\"ql-indent-1\"\u003e\u003cstrong\u003ebin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic flights\u003c/strong\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\u003ch3\u003e\u003cstrong\u003eSend the data file \u0027flights_data.csv\u0027 to the Kafka Topic \u0027flights\u0027\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eflights_data.csv\u003c/strong\u003e is in the data directory of the Fire Install\u003c/li\u003e\u003cli\u003e\u003cstrong\u003ecat flights_data.csv | kafka-console-producer.sh --broker-list localhost:9092 --topic flights (assuming the kafka broker is running at localhost:9092)\u003c/strong\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\u003ch3\u003e\u003cstrong\u003eRun the workflows on the Spark Cluster\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eThis would start a spark streaming job on the Spark Cluster\u003c/strong\u003e\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eYou can keep pushing the data file to the Kafka topic for processing\u003c/strong\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e","widget":"textarea_rich","title":"Comment","description":"Comments for the Workflow","required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"4","name":"FieldSplitter","description":"This node splits the string of the specified input column using the specified delimiter","details":"","examples":"","type":"transform","nodeClass":"fire.nodes.etl.NodeFieldSplitter","x":"71.1181px","y":"267.396px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"inputCol","value":"line","widget":"variable","title":"Input Column","description":"input column name","datatypes":["string"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"outputCols","value":"DAY_OF_MONTH,DAY_OF_WEEK,CARRIER,TAIL_NUM,FL_NUM,ORIGIN_AIRPORT_ID,ORIGIN,DEST_AIRPORT_ID,DEST,CRS_DEP_TIME,DEP_TIME,DEP_DELAY_NEW,CRS_ARR_TIME,ARR_TIME,ARR_DELAY_NEW,CRS_ELAPSED_TIME,DISTANCE","widget":"textarea_medium","title":"Output Columns","description":"new column names