{"name":"Data Cleaning and Feature Generation","uuid":"217e7fff-349d-4eb9-8151-92750231de37","category":"Feature Generation","description":"Workflow for data cleaning and feature generation for ML","parameters":"-","nodes":[{"id":"1","name":"Read_NFL_Data","description":"It reads in CSV files and creates a DataFrame from it","details":"","examples":"","type":"dataset","nodeClass":"fire.nodes.dataset.NodeDatasetCSV","x":"17px","y":"140.625px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"path","value":"data/ks-projects.csv","widget":"textfield","title":"Path","description":"Path of the Text file/directory","required":true,"display":true,"editable":true,"disableRefresh":false},{"name":"separator","value":",","widget":"textfield","title":"Separator","description":"CSV Separator","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"header","value":"true","widget":"array","title":"Header","description":"Does the file have a header row","optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"dropMalformed","value":"false","widget":"array","title":"Drop Malformed","description":"Whether to drop Malformed records or error","optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"outputColNames","value":"[\"ID\",\"name\",\"category\",\"main_category\",\"currency\",\"deadline\",\"goal\",\"launched\",\"pledged\",\"state\",\"backers\",\"country\",\"usd pledged\",\"usd_pledged_real\",\"usd_goal_real\"]","widget":"schema_col_names","title":"Column Names for the CSV","description":"New Output Columns of the SQL","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"outputColTypes","value":"[\"INTEGER\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"STRING\",\"INTEGER\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\"]","widget":"schema_col_types","title":"Column Types for the CSV","description":"Data Type of the Output Columns","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"outputColFormats","value":"[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]","widget":"schema_col_formats","title":"Column Formats for the CSV","description":"Format of the Output Columns","required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"2","name":"DropRowsWithNull","description":"This node creates a new DataFrame by dropping rows containing null values","details":"","examples":"","type":"transform","nodeClass":"fire.nodes.etl.NodeDropRowsWithNull","x":"201.979px","y":"141.604px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"3","name":"DropDuplicateRows","description":"This node creates a new DataFrame by dropping duplicate rows","details":"","examples":"","type":"transform","nodeClass":"fire.nodes.etl.NodeDropDuplicateRows","x":"376.958px","y":"139.583px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"5","name":"Convert to Lower Case","description":"This node performs specified String function on a row","details":"","examples":"","type":"transform","nodeClass":"fire.nodes.etl.NodeStringFunctions","x":"558.958px","y":"137.583px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"inputCols","value":"[\"name\",\"category\",\"main_category\",\"state\"]","widget":"variables","title":"Input Column Name","description":"input column name","datatypes":["string"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"stringFunction","value":"lower","widget":"array","title":"String Function","description":"String Function Name","optionsArray":["trim","upper","lower","lefttrim","righttrim","removewhitespace"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"replaceExistingCols","value":"true","widget":"textfield","title":"ReplaceExistingCols","description":"replaceExistingCols","required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"6","name":"DateTimeFieldExtract","description":"It creates a new DataFrame by extracting Date and Time fields.","details":"Extracts year, month, day of month, hour, minute, second and week of year in different columns.\u003cbr\u003e","examples":"","type":"transform","nodeClass":"fire.nodes.etl.NodeDateTimeFieldExtract","x":"1014.98px","y":"134.583px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"inputCol","value":"launched_date","widget":"variable","title":"Column","description":"The input column name","datatypes":["date","timestamp"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"extractYear","value":"true","widget":"array","title":"Extract Year","description":"Extract Year","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"extractMonth","value":"true","widget":"array","title":"Extract Month","description":"Extract Month","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"extractDayOfMonth","value":"false","widget":"array","title":"Extract Day of Month","description":"Extract Day of Month","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"extractHour","value":"false","widget":"array","title":"Extract Hour","description":"Extract Hour","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"extractMinute","value":"false","widget":"array","title":"Extract Minute","description":"Extract Minute","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"extractSecond","value":"false","widget":"array","title":"Extract Second","description":"Extract Second","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"extractWeekOfYear","value":"false","widget":"array","title":"Extract WeekOfYear","description":"Extract WeekOfYear","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"7","name":"Convert launched, deadline to Date","description":"This node converts a string column to date using the given date/time format","details":"This node converts multiple string columns to date/time.\u003cbr\u003e","examples":"\u003ch2\u003eFormat Examples\u003c/h2\u003e\n\u003cbr\u003e\ndd-MM-yy : 31-01-12\u003cbr\u003e\ndd-MM-yyyy : 31-01-2012\u003cbr\u003e\nMM-dd-yyyy : 01-31-2012\u003cbr\u003e\nyyyy-MM-dd : 2012-01-31\u003cbr\u003e\nyyyy-MM-dd HH:mm:ss : 2012-01-31 23:59:59\u003cbr\u003e\nyyyy-MM-dd HH:mm:ss.SSS : 2012-01-31 23:59:59.999\u003cbr\u003e\nyyyy-MM-dd HH:mm:ss.SSSZ : 2012-01-31 23:59:59.999+0100\u003cbr\u003e\nEEEEE MMMMM yyyy HH:mm:ss.SSSZ : Saturday November 2012 10:45:42.720+0100\u003cbr\u003e","type":"transform","nodeClass":"fire.nodes.etl.NodeMultiStringToDate","x":"757.958px","y":"136.583px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"inputColNames","value":"[\"launched\",\"deadline\"]","widget":"variables_list_select","title":"Columns","description":"Columns","datatypes":["string"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"inputColFormats","value":"[\"yyyy-MM-dd HH:mm:SS\",\"yyyy-MM-dd\"]","widget":"variables_list_textfield","title":"Column Formats","description":"Input Column Formats. eg: yyyy-MM-dd yyyy-MM-dd HH:mm:ss","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"outputColNames","value":"[\"launched_date\",\"deadline_date\"]","widget":"variables_list_textfield","title":"Output Column Names","description":"Output Column Names","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"outputColTypes","value":"[\"DATE\",\"DATE\"]","widget":"variables_list_array","title":"New Data Types","description":"New data types (DATE, TIMESTAMP)","optionsArray":["DATE","TIMESTAMP"],"required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"8","name":"Extract year, month from deadline","description":"It creates a new DataFrame by extracting Date and Time fields.","details":"Extracts year, month, day of month, hour, minute, second and week of year in different columns.\u003cbr\u003e","examples":"","type":"transform","nodeClass":"fire.nodes.etl.NodeDateTimeFieldExtract","x":"1025.94px","y":"298.583px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"inputCol","value":"deadline_date","widget":"variable","title":"Column","description":"The input column name","datatypes":["date","timestamp"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"extractYear","value":"true","widget":"array","title":"Extract Year","description":"Extract Year","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"extractMonth","value":"true","widget":"array","title":"Extract Month","description":"Extract Month","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"extractDayOfMonth","value":"false","widget":"array","title":"Extract Day of Month","description":"Extract Day of Month","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"extractHour","value":"false","widget":"array","title":"Extract Hour","description":"Extract Hour","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"extractMinute","value":"false","widget":"array","title":"Extract Minute","description":"Extract Minute","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"extractSecond","value":"false","widget":"array","title":"Extract Second","description":"Extract Second","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"extractWeekOfYear","value":"false","widget":"array","title":"Extract WeekOfYear","description":"Extract WeekOfYear","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"11","name":"Summary","description":"Summary statistics provide useful information about sample data. eg: measures of spread.","details":"Summary statistics provides useful information about sample data. eg: measures of spread.\u003cbr\u003e\n\u003cbr\u003e\nMore at Spark MLlib/ML docs page : \u003ca href\u003d\"http://spark.apache.org/docs/latest/mllib-statistics.html#summary-statistics\" target\u003d\"_blank\"\u003espark.apache.org/docs/latest/mllib-statistics.html#summary-statistics\u003c/a\u003e\u003cbr\u003e\n\u003cbr\u003e\nSummary Node provides a table consist of informations such as number of non-null entries (count), mean, standard deviation, and minimum and maximum value for each numerical column.\u003cbr\u003e","examples":"","type":"transform","nodeClass":"fire.nodes.ml.NodeSummary","x":"1043.94px","y":"466.583px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"title","value":"Summary","widget":"textfield","title":"Title","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"colNames","value":"[\"backers\",\"launched_date_year\",\"launched_date_month\",\"deadline_date_year\",\"deadline_date_month\",\"goal\",\"pledged\",\"usd pledged\",\"usd_pledged_real\",\"usd_goal_real\"]","widget":"variables","title":"Column Names","description":"Column Names for Summary","datatypes":["integer","long","double","float"],"required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"12","name":"Correlation","description":"calculates the correlation between two series of data.","details":"This node calculates the correlation between two series of data in a common operation in Statistics.\u003cbr\u003e\n\u003cbr\u003e\nMore at Spark MLlib/ML docs page : \u003ca href\u003d\"http://spark.apache.org/docs/latest/mllib-statistics.html#correlations\" target\u003d\"_blank\"\u003espark.apache.org/docs/latest/mllib-statistics.html#correlations\u003c/a\u003e\u003cbr\u003e","examples":"","type":"transform","nodeClass":"fire.nodes.ml.NodeCorrelation","x":"1068.73px","y":"596.583px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"title","value":"Correlation Matrix","widget":"textfield","title":"Title","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"inputCols","value":"[\"backers\",\"pledged\"]","widget":"variables","title":"Input Column for Correlation","description":"Column Names to check correlation ","datatypes":["integer","long","double","float"],"required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"13","name":"HistoGram","description":"Computes a histogram of the data using number of bins evenly spaced between the minimum and maximum of the specific columns.","details":"","examples":"","type":"transform","nodeClass":"fire.nodes.ml.NodeHistoGramCal","x":"1086.15px","y":"741.583px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"inputCols","value":"goal","widget":"variable","title":"ColumnName","description":"Name of column","datatypes":["double","integer","long"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"bins","value":"50","widget":"textfield","title":"Bins","description":"Number of bins","datatypes":["integer"],"required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"14","name":"StandardScaler","description":"StandardScaler transforms a dataset of Vector rows, normalizing each feature to have unit standard deviation and/or zero mean.","details":"StandardScaler transforms a dataset of Vector rows, normalizing each feature to have unit standard deviation and/or zero mean.\u003cbr\u003e\n\u003cbr\u003e\nStandardScaler is an Estimator which can be fit on a dataset to produce a StandardScalerModel; this amounts to computing summary statistics. The model can then transform a Vector column in a dataset to have unit standard deviation and/or zero mean features.\u003cbr\u003e\n\u003cbr\u003e\nIf the standard deviation of a feature is zero, it will return default 0.0 value in the Vector for that feature.\u003cbr\u003e\n\u003cbr\u003e\nMore at Spark MLlib/ML docs page : \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-features.html#standardscaler\" target\u003d\"_blank\"\u003espark.apache.org/docs/latest/ml-features.html#standardscaler\u003c/a\u003e\u003cbr\u003e","examples":"","type":"ml-transformer","nodeClass":"fire.nodes.ml.NodeStandardScaler","x":"159.938px","y":"599.604px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"inputCol","value":"vector_backers","widget":"variable","title":"Input Column","description":"The input column name","datatypes":["vectorudt"],"required":true,"display":true,"editable":true,"disableRefresh":false},{"name":"outputCol","value":"backers_standardized","widget":"textfield","title":"Output Column","description":"The output column name","datatypes":["vectorudt"],"required":true,"display":true,"editable":true,"disableRefresh":false},{"name":"withMean","value":"false","widget":"array","title":"With Mean","description":"Centers the data with mean before scaling.","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"withStd","value":"true","widget":"array","title":"With Standard Dev","description":"Scales the data to unit standard deviation","datatypes":["boolean"],"optionsArray":["true","false"],"required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"15","name":"VectorAssembler","description":"Merges multiple columns into a vector column","details":"","examples":"","type":"ml-transformer","nodeClass":"fire.nodes.ml.NodeVectorAssembler","x":"210.979px","y":"398.625px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"inputCols","value":"[\"backers\"]","widget":"variables","title":"Input Columns","description":"Input column of type - all numeric, boolean and vector","datatypes":["integer","long","double","float","vectorudt"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"outputCol","value":"vector_backers","widget":"textfield","title":"Output Column","description":"Output column name","required":true,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"17","name":"OneHotEncoder","description":"Maps a column of label indices to a column of binary vectors, with at most a single one-value","details":"","examples":"","type":"ml-transformer","nodeClass":"fire.nodes.ml.NodeOneHotEncoder","x":"560.958px","y":"601.583px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"inputCols","value":"[\"ID\",\"name\",\"category\",\"main_category\",\"currency\",\"deadline\",\"goal\",\"launched\",\"pledged\",\"state\",\"backers\",\"country\",\"usd pledged\",\"usd_pledged_real\",\"usd_goal_real\",\"launched_date\",\"deadline_date\",\"launched_date_year\",\"launched_date_month\",\"deadline_date_year\",\"deadline_date_month\",\"vector_backers\",\"backers_standardized\",\"state_indexer\"]","widget":"variables_map","title":"Input Columns","description":"Input columns for encoding","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"outputCols","value":"[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"state_one_hot\"]","widget":"variables_map_edit","title":"Output Columns","description":"Output columns","required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"18","name":"StringIndexer","description":"StringIndexer encodes a string column of labels to a column of label indices","details":"","examples":"","type":"ml-transformer","nodeClass":"fire.nodes.ml.NodeStringIndexer","x":"372.938px","y":"603.938px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"handleInvalid","value":"error","widget":"array","title":"Handle Invalid","description":"Invalid entries to be skipped or thrown error","optionsArray":["skip","error"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"inputCols","value":"[\"ID\",\"name\",\"category\",\"main_category\",\"currency\",\"deadline\",\"goal\",\"launched\",\"pledged\",\"state\",\"backers\",\"country\",\"usd pledged\",\"usd_pledged_real\",\"usd_goal_real\",\"launched_date\",\"deadline_date\",\"launched_date_year\",\"launched_date_month\",\"deadline_date_year\",\"deadline_date_month\",\"vector_backers\",\"backers_standardized\"]","widget":"variables_map","title":"Input Columns","description":"Column containing labels","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"outputCols","value":"[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"state_indexer\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]","widget":"variables_map_edit","title":"Output Columns","description":"Output  columns","required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"19","name":"PrintNRows","description":"Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output","details":"","examples":"","type":"transform","nodeClass":"fire.nodes.util.NodePrintFirstNRows","x":"774.938px","y":"601.604px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"title","value":"Row Values","widget":"textfield","title":"Title","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"n","value":"10","widget":"textfield","title":"Num Rows to Print","description":"number of rows to be printed","required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"20","name":"Documentation","description":"Allows capturing Notes on the Workflow","details":"","examples":"","type":"doc","nodeClass":"fire.nodes.doc.NodeDocLarge","x":"34.5px","y":"12.6667px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"comment","value":"\u003ch1\u003eData Cleaning and Feature Generation\u003c/h1\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\u003cp\u003eThis workflow reads in NFL data. It cleans it and also generates features for further ML.\u003c/p\u003e","widget":"textarea_rich","title":"Comment","description":"Comments for the Workflow","required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"}],"edges":[{"source":"1","target":"2","id":1},{"source":"2","target":"3","id":2},{"source":"3","target":"5","id":3},{"source":"5","target":"7","id":4},{"source":"7","target":"6","id":5},{"source":"6","target":"8","id":6},{"source":"8","target":"11","id":7},{"source":"11","target":"12","id":8},{"source":"12","target":"13","id":9},{"source":"15","target":"14","id":10},{"source":"8","target":"15","id":11},{"source":"14","target":"18","id":12},{"source":"18","target":"17","id":13},{"source":"17","target":"19","id":14}],"dataSetDetails":[],"engine":"scala"}